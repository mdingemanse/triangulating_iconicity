---
title: "Triangulating iconicity: From structure mapping to guessability"
author: "Mark Dingemanse & Stella Punselie"
date: "Updated `r format(Sys.Date())`"
output: github_document
editor_options: 
  chunk_output_type: console
---
  
  ```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=6, fig.path='figures_md/',
                      echo=TRUE, warning=FALSE, message=FALSE)

```

Code notebook for a study of the relation between linguistically informed iconicity coding and experimentally collected guessability scores.

## Setup

```{r preliminaries, results="hide"}
# Packages
list.of.packages <- c("tidyverse","readxl","writexl","ggthemes","gghalves","ggbeeswarm","viridis","lme4","VGAM")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only=T)

# useful functions
`%notin%` <- function(x,y) !(x %in% y) 
mean.na <- function(x) mean(x, na.rm = T)
sd.na <- function(x) sd(x, na.rm = T)

# custom functions
source("TI_functions.R")
```

## Data
Here we load the ground truth version of the coded data and add the independently collected guessability scores from the 2016 Collabra and Language papers.

```{r data}

# get coding data
d = read_excel("data\\ideophones_coded.xlsx") %>% arrange(filename)

coding_categories <- d %>% dplyr::select(matches('_'),-matches('notes|meaning')) %>% names()

# add guessability scores from the Collabra and Language studies.

d.scores = read_excel("data\\ideophones_guessability.xlsx") %>%
  dplyr::select(-category)
d <- left_join(d,d.scores,by=c("ideophone","language","study" = "paper"))

# add logodds (for when we run stats: it's more sensible to predict against logodds than raw proportion correct)
d <- d %>%
  group_by(study) %>%
  mutate(logodds = probitlink(score))

# add Z score to account for differences in base success rate of Collabra and Language Studies
d <- d %>%
  group_by(study) %>%
  mutate(score_z = scale(score,center=T,scale=T))

```

We add congruency measures that link F and M elements. 

* TO DISCUSS: We need to think about the evidential value of each of the congruency measures. Most apply to many words, which is good. If some of them only capture a few (as `C_durative` and `C_weight_tone` seem to do), they are not so interesting because they don't really capture recurring iconic mappings in the data. 
* Discussed: This made us realize a need to name `M_durative` to `M_long`, covering extent not just in time but also in space (a very concrete kind of mapping for `F_finallength`. 

```{r congruency_1}

# using ifelse() statements that essentially say, if these conditions are true, use 1, otherwise 0
d <- d %>%
  mutate(C_modality = ifelse(M_sound == 1,1,0),
         C_iterative = ifelse(F_redup == 1 & M_distribution == 1,1,0),
         C_irregular = ifelse(F_redupmod == 1 & M_irregular == 1,1,0),
         C_closure = ifelse(F_closedsyllable == 1 & M_abrupt == 1,1,0),
         C_punctual = ifelse(F_monosyllabic == 1 & M_punctual == 1,1,0),
         C_long = ifelse(F_finallength == 1 & M_long == 1,1,0),
         C_weight_voice = ifelse((F_voice == 0 & M_weight == 0) | (F_voice == 2 & M_weight) == 2,1,0),
         C_weight_vowel = ifelse((F_vowelquality == 0 & M_weight == 0) | (F_vowelquality == 2 & M_weight == 2),1,0),
         C_weight_tone = ifelse((F_intonation == 0 & M_weight == 2) | (F_intonation == 2 & M_weight == 0),1,0)
         )

# are some mappings mutually exclusive? then it might be slightly more elegant to combine them
d %>%
  mutate(C_event = C_iterative + C_punctual) %>%
  dplyr::select(ideophone,meaning_NL,language,C_iterative,C_punctual,C_event) %>%
  filter(C_event > 1)

d %>%
  mutate(C_exclusive = C_long + C_closure) %>%
  dplyr::select(ideophone,meaning_NL,language,C_iterative,C_closure,C_exclusive) %>%
  filter(C_exclusive > 1)



# add some cumulative iconicity scores
d <- d %>%
  mutate(C_cumulative = C_modality + C_iterative + C_irregular + C_closure + C_punctual + C_long + C_weight_voice + C_weight_vowel + C_weight_tone) %>%
  mutate(C_any1 = ifelse(C_cumulative == 0,0,1),
         C_atleast2 = ifelse(C_cumulative > 1,1,0),
         C_ternary = ifelse(C_cumulative == 0,0,
                            ifelse(C_cumulative == 1,1,
                                   ifelse(C_cumulative == 2,2,3))))

# cumulative scores can be further refined by considering only features that work for this sample â€” e.g., since C_irregular only adds noise, it may be excluded 
d <- d %>%
  mutate(C_simple = C_modality + C_iterative + C_closure + C_punctual + C_weight_tone + C_weight_vowel)

# write this dataset for use in the next step
write.csv(d,file="data/ideophones_coded_guessed.csv")

d %>%
  group_by(C_cumulative) %>%
  summarise(n=n(),score=mean.na(score))

d %>%
  group_by(C_ternary) %>%
  summarise(n=n(),score=mean.na(score))

d %>%
  group_by(C_simple) %>%
  summarise(n=n(),score=mean.na(score))


```


## Plots

A quick first look at some congruency measures. Uses a custom plotting function `icoplot()`, which is a wrapper for a ggplot object constructed with `geom_dotplot`.


```{r icoplots}

# make a copy dp of the data in which we convert some measures to factors for easy plotting & facetting
tofactors <- paste(c("language|category|study|group",names(d[grep('C_',names(d))])),collapse = "|")
dp <- d
dp[,grep(tofactors,names(dp))] <- lapply(dp[,grep(tofactors,names(dp))], as.factor)

# all data points by language
icoplot() # icoplot() is loaded from TI_functions.R

icoplot("C_modality")
icoplot("C_iterative")
icoplot("C_irregular")
icoplot("C_punctual")
icoplot("C_long")
icoplot("C_weight_voice")
icoplot("C_weight_vowel")
icoplot("C_weight_tone")

icoplot("C_cumulative")

icoplot("C_any1")
icoplot("C_atleast2")
icoplot("C_ternary")

# blank plot can be useful as background for slides
ggplot(data=dp, aes(x=study,y=score)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none",axis.title.x=element_blank(),plot.margin=margin(0,0,10,0)) + 
  stat_summary(fun.y=median,geom="point",size=8,shape=21,stroke=1,fill="white",colour="#c9c9c9") +
  geom_dotplot(colour="white",fill="#c9c9c9",stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center")

```

### Tinkering with plots
Just trying different ways of visualizing the data to find the most helpful and transparent one. 

```{r visuals}


icoplot("C_simple")

ggplot(data=dp, aes(x="all",y=score_z)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point(side="l") +
  geom_half_violin(side="r") +
  NULL

ggplot(data=dp, aes(x=C_simple,y=logodds)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point() +
  NULL
ggplot(data=dp, aes(x=C_simple,y=score_z)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point() +
  NULL


ggplot(data=dp, aes(x=C_simple,y=logodds,color=C_simple)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_dotplot() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  NULL


ggplot(data=dp, aes(x=C_ternary,y=logodds,color=C_ternary,fill=C_ternary)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_point_panel() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  facet_grid(~ study)

ggplot(data=dp, aes(x=C_ternary,y=logodds,color=C_ternary,fill=C_ternary)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_dotplot(dotsize=0.8) +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  facet_grid(~ study)

ggplot(data=dp, aes(x=C_atleast2,y=logodds,color=C_atleast2,fill=C_atleast2)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_dotplot(dotsize=0.4,stackratio=0.8,method="histodot") +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  facet_grid(~ study)



ggplot(data=dp, aes(x=category,y=logodds,color=category)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_point_panel() +
  NULL

ggplot(data=dp, aes(x=language,y=logodds,color=language)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_point_panel() +
  NULL

ggplot(data=d, aes(x=language,y=C_ternary,color=language)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_point_panel() +
  NULL

```

## Exploring congruency blind spots
What are we not capturing? Our coding and congruency measures are designed to be reproducible and human-codable. They are not exhaustive, and there may well be aspects that we are missing. Some ideophones may also be guessed relatively high for reasons other than form-meaning analogies (e.g., they had a very unattractive foil or presented unforeseen confounds). Here we explore the congruency data to find highly guessed ideophones that our coding did not (yet) identify as having iconic mappings. We also look at the other end: ideophones coded as having an iconic mapping but not doing well in the binary forced choice task. 

If we sort by score most of the blindspots are from the Collabra study, which had a less forbidding design and therefore a higher baseline score. 

```{r congruency_blindspots}


d %>%
  filter(C_cumulative == 0, logodds >0) %>%
  dplyr::select(filename,ideophone,meaning,meaning_NL,language,logodds,score) %>%
  arrange(-score) %>% ungroup %>%
  slice(1:10)
```


```{r congruency_underperformers}
# the reverse is also interesting: which ideophones were coded as having iconic mappings yet were not guessed greatly?

d %>%
  filter(C_cumulative > 0, logodds < -0.25) %>%
  dplyr::select(filename,ideophone,meaning,meaning_NL,C_cumulative,language,logodds,score) %>%
  arrange(score) %>% ungroup() %>%
  slice(1:10)


```

## Stats
As the visualizations already make clear there is a non-trivial positive relation between the presence of iconic mappings (in a cumulative sense) and the guessability score determined in experimental work.

```{r congruency_stats_1}

# simplest thing we can do is a correlation

cor.test(d$logodds,d$C_cumulative)
cor.test(d$score_z,d$C_cumulative)


```
