---
title: "Triangulating iconicity: Coding analysis"
author: "Mark Dingemanse & Stella Punselie"
date: "Updated `r format(Sys.Date())`"
output: github_document
editor_options: 
  chunk_output_type: console
---
  
  ```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=6, fig.path='figures_md/',
                      echo=TRUE, warning=FALSE, message=FALSE)

```

Code notebook for a study of the relation between linguistically informed iconicity coding and experimentally collected guessability scores.

## Setup

```{r preliminaries, results="hide"}
# Packages
list.of.packages <- c("tidyverse","readxl","writexl","ggthemes","gghalves","ggbeeswarm","viridis","lme4","VGAM","cowplot")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only=T)

# useful functions
`%notin%` <- function(x,y) !(x %in% y) 
mean.na <- function(x) mean(x, na.rm = T)
sd.na <- function(x) sd(x, na.rm = T)

# custom functions
source("TI_functions.R")
```

## Data
Here we load the ground truth version of the coded data and add the independently collected guessability scores from the 2016 Collabra and Language papers.

```{r data}

# get consensus coding data
d = read_excel("data\\ideophones_coded.xlsx") %>% arrange(filename)

# add guessability scores from the Collabra and Language studies.

d.scores = read_excel("data\\ideophones_guessability.xlsx") %>%
  dplyr::select(-category)
d <- left_join(d,d.scores,by=c("ideophone","language","study" = "paper"))

# add logodds (for when we run stats: it's more sensible to predict against logodds than raw proportion correct)
d <- d %>%
  group_by(study) %>%
  mutate(logodds = probitlink(score))

# add Z score to make scores more comparable in plots across studies
d <- d %>%
  group_by(study) %>%
  mutate(score_z = scale(score,center=T,scale=T))

# get ratings data
d.ratings <- read_xlsx("data\\ideophones_rated_means.xlsx") %>%
  dplyr::select(-category,-list,-item)
d <- left_join(d,d.ratings,by=c("filename","study","language"))

# add z score for ratings
d$rating_z <- scale(d$rating,center=T,scale=T)

# write this dataset as the fullest dataset
write.csv(d,file="data/ideophones_coded_guessed_rated.csv")
write_xlsx(d,path="data/ideophones_coded_guessed_rated.xlsx")

# also write a simplified copy for easy inspection in Excel (helpful when writing)
d %>%
  dplyr::select(ideophone,meaning,language,category,meaning_NL,study,score,rating,C_aspect,C_magnitude,C_modality,C_length,C_irregular,C_cumulative) %>%
  write_xlsx(path="data/ideophones_coded_guessed_rated_simplified.xlsx")


```

## Figures
Here we generate some descriptive stats and create the main figures for the paper.

```{r descriptive_stats}

d %>%
  group_by(study) %>%
  summarize(max=max(score),min=min(score),mean=mean.na(score))

```

### Figure: Overview panel
The overview panel is created separately but we use the data from the guessability studies as a canvas.

```{r figures_paper_guessability_canvas}

# make a copy dp of the data in which we convert some measures to factors for easy plotting & facetting
tofactors <- paste(c("language|category|study|group",names(d[grep('C_',names(d))])),collapse = "|")
dp <- d
dp[,grep(tofactors,names(dp))] <- lapply(dp[,grep(tofactors,names(dp))], as.factor)


# blank plot can be useful as a canvas 
ggplot(data=dp, aes(x=study,y=score)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none",axis.title.x=element_blank(),plot.margin=margin(0,0,10,0)) + 
  stat_summary(fun=median,geom="point",size=8,shape=21,stroke=1,fill="white",colour="#c9c9c9") +
  geom_dotplot(colour="white",fill="black",stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center")

ggsave("figures\\paper-guessability-blank.pdf",height=5,width=7.5)

d %>% filter(filename=="Korean_23_Motion_org") %>% View()


```


### Figure: Guessability by study and iconicity rating

```{r figures_paper_guessability_rating}
tofactors <- paste(c("language|category|study|group",names(d[grep('C_',names(d))])),collapse = "|")
dp <- d
dp[,grep(tofactors,names(dp))] <- lapply(dp[,grep(tofactors,names(dp))], as.factor)


# panel A: scores by study and cumulative iconicity
pA <- ggplot(data=dp, aes(x=study,y=score,fill=study,colour=study)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none") + 
  labs(title="Guessability by study",
       x="study",
       y="guessability (% correct)") +
  geom_dotplot(stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center") +
  NULL

pB <- ggplot(data=dp, aes(x=rating,y=score,fill=study,colour=study)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none") +
  labs(title="Guessability (both studies) by iconicity rating",
       x="iconicity rating",
       y="") +
  geom_point(size=2.0,shape=21) +
  geom_smooth(method="lm") +
  NULL

plot_grid(pA,pB,labels=c("A","B"),label_size=14,rel_widths = c(1.4,2))
ggsave("figures\\paper_panelAB_guessing_rating.png",height=5,width=9)



```

### Figure: Guessability and cumulative iconicity

```{r figures_paper_guessability_coding}

# make a copy dp of the data in which we convert some measures to factors for easy plotting & facetting
tofactors <- paste(c("language|category|study|group",names(d[grep('C_',names(d))])),collapse = "|")
dp <- d
dp[,grep(tofactors,names(dp))] <- lapply(dp[,grep(tofactors,names(dp))], as.factor)


# panel A: scores by study and cumulative iconicity
pA <- ggplot(data=dp, aes(x=study,y=score,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none") + 
  labs(title="Guessability by study",
       x="study",
       y="guessability (% correct)") +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  stat_summary(fun.y=median,geom="point",size=8,shape=21,stroke=1,fill="white") +
  geom_dotplot(stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center") +
  NULL

pB <- ggplot(data=dp, aes(x=C_cumulative,y=score_z,colour=C_cumulative)) +
  theme_tufte() + theme(legend.position="none") +
  labs(title="Guessability (both studies) by cumulative iconicity",
       x="cumulative iconicity",
       y=expression('guessability ('~italic(z)~')')) +
  geom_half_boxplot() +
  geom_half_point() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  NULL

plot_grid(pA,pB,labels=c("A","B"),label_size=14,rel_widths = c(1.4,2))
ggsave("figures\\paper_panelAB.png",height=5,width=9)


```

### Figure: Ratings and cumulative iconicity

```{r ratings_and_C}


# panel A: ratings by study and cumulative iconicity
pA <- ggplot(data=dp, aes(x="",y=rating,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() +  ylim(1,5) + theme(legend.position="none") + 
  labs(title="Iconicity ratings for 239 ideophones",
       x="all ideophones",
       y="mean iconicity rating") +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  geom_beeswarm(cex=2.5) +
  NULL

pB <- ggplot(data=dp, aes(x=C_cumulative,y=rating,colour=C_cumulative)) +
  theme_tufte() +  ylim(1,5) + theme(legend.position="none") +
  labs(title="... by independently coded structural correspondences",
       x="cumulative iconicity",
       y="mean iconicity rating") +
  geom_half_boxplot() +
  geom_half_point() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  NULL

plot_grid(pA,pB,labels=c("A","B"),label_size=14,rel_widths = c(1.4,2))
ggsave("figures\\paper_panelAB_ratings.png",height=5,width=9)


```

### Figure: Mappings and semantic domains 

```{r figure_mappings_domains}

library(forcats)
dp.categories <- d %>%
  filter(category %notin% "Other") %>%
  mutate(category = fct_reorder(category, -C_cumulative, .fun='mean')) %>%
  mutate(category_binary = ifelse(category %in% c("Sound","Motion"),"SoundMotion","ColorvisualShapeTexture")) %>%
  mutate(C_nosound = C_aspect + C_length + C_irregular + C_magnitude) %>% # for control analysis
  mutate(C_strongestpredictors = C_aspect + C_length + C_modality ) # for another control analysis


dp.categories %>%
  group_by(category) %>%
  summarise(n=n(),mean_C=mean.na(C_cumulative),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)

dp.categories %>%
  group_by(category) %>%
  summarise(n=n(),mean_C=mean.na(C_strongestpredictors),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)


dp.categories %>%
  ungroup() %>%
  group_by(category_binary) %>%
  summarise(n=n(),mean_C=mean.na(C_cumulative),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)

group1 <- subset(dp.categories, category_binary == "SoundMotion")$C_cumulative
group2 <- subset(dp.categories, category_binary == "ColorvisualShapeTexture")$C_cumulative
t.test(group1,group2)
library(effsize)
cohen.d(group1,group2)


# also when we exclude C_modality? yes
dp.categories %>%
  group_by(category) %>%
  summarise(n=n(),mean_C=mean.na(C_nosound),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)
dp.categories %>%
  group_by(category_binary) %>%
  summarise(n=n(),mean_C=mean.na(C_nosound),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)

group1 <- subset(dp.categories, category_binary == "SoundMotion")$C_nosound
group2 <- subset(dp.categories, category_binary == "ColorvisualShapeTexture")$C_nosound
t.test(group1,group2)
cohen.d(group1,group2)


ggplot(data=dp.categories, aes(y=C_cumulative,x=category,colour=C_cumulative)) +
  theme_tufte() + theme(legend.position="none") +
  labs(title="Cumulative iconicity by semantic domain") +
  geom_half_violin() +
  geom_half_point() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  NULL

ggplot(data=dp.categories, aes(y=C_cumulative,x=category,colour=C_cumulative)) +
  theme_tufte() + theme(legend.position="none") +
  labs(title="Cumulative iconicity by semantic domain") +
  geom_hex() +
  NULL



```



### Raincloud plots
While the icoplots provide a useful first visualisation, for in a paper we would probably want to use something like raincloud plots that show key features of the distribution across groups.

```{r visuals}


# panel A: scores by study and cumulative iconicity
ggplot(data=dp, aes(x=study,y=score,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none",axis.title.x=element_blank()) + 
  labs(title="Guessability by study and cumulative iconicity") +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  stat_summary(fun.y=median,geom="point",size=8,shape=21,stroke=1,fill="white") +
  geom_dotplot(stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center")


ggplot(data=dp, aes(x=C_cumulative,y=logodds)) +
  theme_tufte() +
  labs(title="Guessability (log odds) by cumulative iconicity",
       x="cumulative iconicity",
       y="guessability (log odds)") +
  geom_half_boxplot() +
  geom_half_point() +
  NULL

ggplot(data=dp, aes(x=C_any1,y=logodds)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point() +
  NULL


ggplot(data=dp, aes(x=C_atleast2,y=logodds)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point() +
  NULL

ggplot(data=dp, aes(x=C_ternary,y=logodds)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point() +
  NULL


ggplot(data=dp, aes(x="all",y=score_z)) +
  theme_tufte() +
  geom_half_boxplot() +
  geom_half_point(side="l") +
  geom_half_violin(side="r") +
  NULL

ggplot(data=dp, aes(x=C_cumulative,y=logodds,color=C_cumulative,fill=C_cumulative)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_point_panel() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) 

icoplot("C_cumulative")

ggplot(data=dp, aes(x=C_cumulative,y=logodds,color=C_cumulative,fill=C_cumulative)) +
  theme_tufte() +
  geom_half_violin() +
  geom_half_point_panel() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  facet_grid(~ study)

```


### Dotplots

A quick look at some congruency measures. Uses a custom plotting function `icoplot()`, which is a wrapper for a ggplot object constructed with `geom_dotplot`.


```{r icoplots}


# all data points by language
icoplot() # icoplot() is loaded from TI_functions.R

icoplot("C_modality")
icoplot("C_aspect")
icoplot("C_length")
icoplot("C_magnitude")
icoplot("C_irregular")
icoplot("C_cumulative")

# how do the constituents of C_magnitude fare?
icoplot("C_magnitude")
icoplot("C_weight_voice")
icoplot("C_weight_vowel")
icoplot("C_weight_tone")

icoplot("C_any1")
icoplot("C_atleast2")
icoplot("C_ternary")
icoplot("C_simple")

# blank plot can be useful as background for slides
ggplot(data=dp, aes(x=study,y=score)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none",axis.title.x=element_blank(),plot.margin=margin(0,0,10,0)) + 
  stat_summary(fun.y=median,geom="point",size=8,shape=21,stroke=1,fill="white",colour="#c9c9c9") +
  geom_dotplot(colour="white",fill="#c9c9c9",stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center")

# facet by language to discover crosslinguistic diversity
ggplot(data=dp, aes(x=study,y=score)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none",axis.title.x=element_blank(),plot.margin=margin(0,0,10,0)) + 
  stat_summary(fun.y=median,geom="point",size=8,shape=21,stroke=1,fill="white",colour="#c9c9c9") +
  geom_dotplot(colour="white",fill="#c9c9c9",stackgroups=T,dotsize=1.5,binwidth=0.01,binaxis="y",stackdir = "center")


```


## Numbers

### Coding and guessability
As the visualizations already make clear there is a non-trivial positive relation between the presence of iconic mappings (in a cumulative sense) and the guessability score determined in experimental work.

The simplest thing to do is a simple correlation. Looks like there is an r=0.30 correlation between logodds and C_cumulative.

```{r congruency_stats_1}

# simplest thing we can do is a correlation. 

cor.test(d$logodds,d$C_cumulative,method="pearson")

d.Collabra <- d %>% filter(study == "Collabra")
d.Language <- d %>% filter(study == "Language")
cor.test(d.Collabra$logodds,d.Collabra$C_cumulative,method="pearson")
cor.test(d.Language$logodds,d.Language$C_cumulative,method="pearson")

p0 <- cor.test(d$logodds,d$C_cumulative,method="pearson")$p.value
p1 <- cor.test(d.Collabra$logodds,d.Collabra$C_cumulative,method="pearson")$p.value
p2 <- cor.test(d.Language$logodds,d.Language$C_cumulative,method="pearson")$p.value
p.adjust(c(p0,p1,p2),method="bonferroni")


```

But it's probably more useful to predict logodds score on the basis of what we know about paper (= a proxy for method) and the main measures of form-meaning congruence. For this we can use logistic regression.

A null model `m0` predices logodds by paper, controlling for item-level differences. A model `m1` with cumulative congruence as an additional fixed effect fares significantly better.

For the fixed effects, m1 lists a 0.182 improvement in logodds for C_cumulative. According to my interpretation this means that every added iconic feature leads to a ~7% boost in proportion correct.

Also note that, accounting for possible difference in coded cumulative iconicity across studies, the Language paper has a negative fixed effect of -0.524, which translates to a 19% guessability penalty for the relatively unforgiving method of the Language study (or alternatively, a similar-sized boost for the methods of the Collabra study).

```{r congruency_stats_2}


m0 <- lmer(logodds ~ study + (1|ideophone), data=d)
m1 <- lmer(logodds ~ study + C_cumulative + (1|ideophone), data=d)
anova(m0,m1)

fixef(m1)

probitlink(0.1823,inverse=T)-0.5
probitlink(-0.5242,inverse=T)-0.5



```

We can assess the relative weight of different features using model comparison. We build models by adding the congruency measures in rank order of attestation in the coded data. Doing this we find that C_aspect, C_modality and C_length are responsible for the bulk of the variance. Compared to the null model that only represents the baseline difference between studies, model `m8` fares significantly better (log likelihood difference = 21.3).

The model estimates given in the output of `fixef(m8)` represent the contribution of a given fixed effect while controlling for others, but they are NOT additive (i.e. can't be summed to arrive at the effect of `C_cumulative`).

* `C_aspect`: 0.181 logodds (+7% boost)
* `C_modality`: 0.177 logodds (+7% boost)
* `C_length`: 0.443 logodds (+17% boost)

```{r congruency_stats_3}

m3 <- lmer(logodds ~ study + C_aspect + (1|ideophone), data=d)
m4 <- lmer(logodds ~ study + C_aspect + C_magnitude + (1|ideophone), data=d)
m5 <- lmer(logodds ~ study + C_aspect + C_magnitude + C_modality + (1|ideophone), data=d)
m6 <- lmer(logodds ~ study + C_aspect + C_magnitude + C_modality + C_length + (1|ideophone), data=d)
m7 <- lmer(logodds ~ study + C_aspect + C_magnitude + C_modality + C_length + C_irregular + (1|ideophone), data=d)
m8 <- lmer(logodds ~ study + C_aspect + C_modality + C_length + (1|ideophone), data=d)

anova(m0,m3) # aspect helps
anova(m3,m4) # magnitude doesn't additionally help
anova(m4,m5) # modality helps
anova(m3,m5) # modality helps also relative to m3
anova(m5,m6) # length helps
anova(m6,m7) # irregular doesn't additionally help
anova(m5,m8) # aspect + modality + length is where it's at
# so m8 is the best performing most complex model
anova(m0,m8)
summary(m8)
fixef(m8)

probitlink(fixef(m8)[1],inverse=T)-0.5
probitlink(fixef(m8)[2],inverse=T)-0.5
probitlink(fixef(m8)[3],inverse=T)-0.5
probitlink(fixef(m8)[4],inverse=T)-0.5
probitlink(fixef(m8)[5],inverse=T)-0.5



```

### Semantic domains
Our prediction is that Sound and Motion ideophones should show more structural correspondences than the other domains. This is borne out.

```{r coding_semanticdomains} 

library(forcats)
dp.categories <- d %>%
  filter(category %notin% "Other") %>%
  mutate(category = fct_reorder(category, -C_cumulative, .fun='mean')) %>%
  mutate(category_binary = ifelse(category %in% c("Sound","Motion"),"SoundMotion","ColorvisualShapeTexture")) %>%
  mutate(C_nosound = C_aspect + C_length + C_irregular + C_magnitude) %>% # for control analysis
  mutate(C_strongestpredictors = C_aspect + C_length + C_modality ) # for another control analysis


dp.categories %>%
  group_by(category) %>%
  summarise(n=n(),mean_C=mean.na(C_cumulative),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)

dp.categories %>%
  group_by(category) %>%
  summarise(n=n(),mean_C=mean.na(C_strongestpredictors),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)


dp.categories %>%
  ungroup() %>%
  group_by(category_binary) %>%
  summarise(n=n(),mean_C=mean.na(C_cumulative),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)

group1 <- subset(dp.categories, category_binary == "SoundMotion")$C_cumulative
group2 <- subset(dp.categories, category_binary == "ColorvisualShapeTexture")$C_cumulative
t.test(group1,group2)
library(effsize)
cohen.d(group1,group2)


# also when we exclude C_modality? yes
dp.categories %>%
  group_by(category) %>%
  summarise(n=n(),mean_C=mean.na(C_nosound),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)
dp.categories %>%
  group_by(category_binary) %>%
  summarise(n=n(),mean_C=mean.na(C_nosound),mean_rating=mean.na(rating),mean_score=mean.na(score)) %>%
  arrange(-mean_C)

group1 <- subset(dp.categories, category_binary == "SoundMotion")$C_nosound
group2 <- subset(dp.categories, category_binary == "ColorvisualShapeTexture")$C_nosound
t.test(group1,group2)
cohen.d(group1,group2)

```

We can also look in more detail at the relative differences by semantic domain by building a mixed model that predicts cumulative iconicity with domain as a predictor.

```{r coding_category_lme}

m0 <- lm(C_cumulative ~ category, data=d)
effsizes(m0)

```

Another prediction is that Sound and Motion ideophones should receive higher iconicity ratings than other domains. This prediction is also borne out.

```{r rating_domains}

group1 <- subset(dp.categories, category_binary == "SoundMotion")$rating
group2 <- subset(dp.categories, category_binary == "ColorvisualShapeTexture")$rating
t.test(group1,group2)
cohen.d(group1,group2)




```

### Coding and ratings

As above, the simplest thing to do is run a simple correlation: there is an r=0.43 correlation between meaning iconicity ratings and cumulative iconicity.

```{r coding_ratings}

cor.test(d$rating_z,d$C_cumulative,method="pearson")

```

As above, we can go a bit deeper by using mixed effects modelling. We expect a smaller effect of study on the ratings, as the difference in design in terms of selection of foils falls away. However, the studies are also different in terms of 

```{r coding_ratings_lme}

m0 <- lmer(rating ~ study + (1|ideophone), data=d)
m1 <- lmer(rating ~ study + C_cumulative + (1|ideophone), data=d)
anova(m0,m1)

fixef(m1)

```

We can assess the relative weight of different features using model comparison. We build models by adding the congruency measures in rank order of attestation in the coded data. Doing this we find that C_aspect, C_modality and C_length are responsible for the bulk of the variance. Compared to the null model that only represents the baseline difference between studies, model `m8` fares significantly better (log likelihood difference = 21.3).

The model estimates given in the output of `fixef(m8)` represent the contribution of a given fixed effect while controlling for others, but they are NOT additive (i.e. can't be summed to arrive at the effect of `C_cumulative`).

* `C_aspect`: 0.181 logodds (+7% boost)
* `C_modality`: 0.177 logodds (+7% boost)
* `C_length`: 0.443 logodds (+17% boost)

```{r congruency_stats_3}

m3 <- lmer(rating ~ study + C_aspect + (1|ideophone), data=d)
m4 <- lmer(rating ~ study + C_aspect + C_magnitude + (1|ideophone), data=d)
m5 <- lmer(rating ~ study + C_aspect + C_magnitude + C_modality + (1|ideophone), data=d)
m6 <- lmer(rating ~ study + C_aspect + C_magnitude + C_modality + C_length + (1|ideophone), data=d)
m7 <- lmer(rating ~ study + C_aspect + C_magnitude + C_modality + C_length + C_irregular + (1|ideophone), data=d)
m8 <- lmer(rating ~ study + C_aspect + C_modality + C_length + (1|ideophone), data=d)

anova(m0,m3) # aspect helps
anova(m3,m4) # magnitude doesn't additionally help
anova(m4,m5) # modality helps
anova(m3,m5) # modality helps also relative to m3
anova(m5,m6) # length helps
anova(m6,m7) # irregular doesn't additionally help
anova(m5,m8) # aspect + modality + length is where it's at
# so m8 is the best performing most complex model
anova(m0,m8)
summary(m8)
fixef(m8)



```

### Control analysis: results stand even when leaving out C_modality

The `C_modality` congruence measure is intended to capture the fact that spoken words can show a range of acoustic similarities to sonic events, independently from other structural correspondences (in other words, it separates imagic iconicity from Gestalt iconicity and relative iconicity). We don't code for specific acoustic correspondences, because these would be by nature only apply to ideophones evocative of sound and would greatly complicate the coding scheme.

This makes it the least fine-grained coding category. And given that it applies to a semantic domain that is known, from prior work and first principles, to be easiest to guess, one could think of `C_modality` as just giving sound words a leg up in the cumulative scores. Therefore, as a control, it is useful to know whether the patterns we find hold up even if we disregard `C_modality` entirely.

```{r sound_off}

# we add C_nosound as a cumulative measure that excludes modality
d <- d %>%
  mutate(C_nosound = C_aspect + C_length + C_irregular + C_magnitude)

# recreate dp to include C_nosound
tofactors <- paste(c("language|category|study|group",names(d[grep('C_',names(d))])),collapse = "|")
dp <- d
dp[,grep(tofactors,names(dp))] <- lapply(dp[,grep(tofactors,names(dp))], as.factor)


d %>%
  group_by(C_nosound) %>%
  summarise(n=n(),score=mean.na(score))

ggplot(data=dp, aes(x=C_nosound,y=score_z,colour=C_nosound)) +
  theme_tufte() + theme(legend.position="none") +
  labs(title="Guessability (both studies) by cumulative iconicity",
       x="cumulative iconicity (excluding modality)",
       y=expression('guessability ('~italic(z)~')')) +
  geom_half_boxplot() +
  geom_half_point() +
  scale_fill_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  scale_colour_viridis(option="plasma",discrete=T,begin=0.3,end=0.9) +
  NULL

```


There is an r=0.26 correlation between logodds and C_sound across the studies. This is present in both studies.

```{r congruency_stats_nosound_1}

# simplest thing we can do is a correlation. 

cor.test(d$logodds,d$C_nosound,method="pearson")

d.Collabra <- d %>% filter(study == "Collabra")
d.Language <- d %>% filter(study == "Language")
cor.test(d.Collabra$logodds,d.Collabra$C_nosound,method="pearson")
cor.test(d.Language$logodds,d.Language$C_nosound,method="pearson")

p0 <- cor.test(d$logodds,d$C_nosound,method="pearson")$p.value
p1 <- cor.test(d.Collabra$logodds,d.Collabra$C_nosound,method="pearson")$p.value
p2 <- cor.test(d.Language$logodds,d.Language$C_nosound,method="pearson")$p.value
p.adjust(c(p0,p1,p2),method="bonferroni")


```

The mixed effects models look much the same.
A null model `m0` predices logodds by paper, controlling for item-level differences. A model `m1` with cumulative congruence as an additional fixed effect fares significantly better.

For the fixed effects, m1 lists a 0.205 improvement in logodds for `C_nosound`. According to my interpretation this means that every added iconic feature leads to an ~8% boost in proportion correct. The lower baseline for the Language set is estimated as -0.513, which translates to a 19.5% guessability penalty.

```{r congruency_stats_nosound2}

m0 <- lmer(logodds ~ study + (1|ideophone), data=d)
m1 <- lmer(logodds ~ study + C_nosound + (1|ideophone), data=d)
anova(m0,m1)

fixef(m1)

probitlink(0.205,inverse=T)-0.5
probitlink(-0.513,inverse=T)-0.5



```


## Exploring coding sensitivity and congruency blind spots
What are we not capturing? Our coding and congruency measures are designed to be reproducible and human-codable. They are not exhaustive, and there may well be aspects that we are missing. Some ideophones may also be guessed relatively high for reasons other than form-meaning analogies (e.g., they had a very unattractive foil or presented unforeseen confounds). Here we explore the congruency data to find highly guessed ideophones that our coding did not (yet) identify as having iconic mappings. We also look at the other end: ideophones coded as having an iconic mapping but not doing well in the binary forced choice task. 

If we sort by score most of the blindspots are from the Collabra study, which had a less forbidding design and therefore a higher baseline score. 

```{r congruency_blindspots}


d %>%
  filter(C_cumulative == 0, score_z > 0.5) %>%
  dplyr::select(filename,ideophone,meaning,meaning_NL,language,logodds,score) %>%
  arrange(-score) %>% ungroup %>%
  slice(1:10)

```

Coding sensitivity varies by feature, in part because not all are equally frequent. For instance, `C_weight_tone` captures ideophones that have high tone/intonation and small/light meaning or conversely low tone/intonation and big/heavy meaning. 

```{r coding_sensitivity}

icoplot("C_weight_tone")

d %>%
  group_by(language) %>%
  filter(C_weight_tone == 1) %>%
  summarise(n=n(),score=mean.na(score),rating=mean.na(rating))

d %>%
  group_by(language) %>%
  filter(C_weight_tone == 1) %>%
  View()


```

### Variation by language

Although we have focused on cross-linguistically attested features, features may also vary by language. For instance, irregularity may work somewhat in Japanese, Korean and Ewe, the 4 Semai ideophones scored as showing this mapping have a mean accuracy score of 0.45, dragging down the average. It looks like partial reduplication really has a different function in Semai, and one that is not captured by our coding scheme.


```{r coding_by_language}

d %>%
  group_by(language) %>%
  filter(C_irregular == 1) %>%
  summarise(n=n(),score=mean.na(score),rating=mean.na(rating),C=mean.na(C_cumulative))

d %>%
  group_by(language) %>%
  filter(C_irregular == 1) %>%
  dplyr::select(ideophone,meaning,language,category,score,rating,C_irregular,C_cumulative) %>%
  View()


mS0 <- lmer(logodds ~ study + (1|ideophone), data=d)
mS1 <- lmer(logodds ~ study + language + (1|ideophone), data=d) # fails to converge
mS2 <- lmer(logodds ~ study + C_aspect + C_modality + C_length + (1|ideophone), data=d)
mS3 <- lmer(logodds ~ study + C_aspect + C_modality + C_length + language + (1|ideophone), data=d) 

anova(mS2,mS3)

fixef(mS3)

```



One might conclude from that language would be a relevant factor to take into account in the statistical models. But its influence is not very large. If we add it to the most complete model above, the fit is marginally improved, but the difference is not of the same magnitude as other factors. Also, language is partly confounded with quality of recordings, which are lab recordings for Ewe, Korean, Japanese and field recordings for Siwu and Semai. We can dummy code this as a new variable to check its effect.

```{r coding_by_audio}

d <- d %>%
  mutate(audio = ifelse(language %in% c("Siwu","Semai"),"field","lab"))

d %>%
  group_by(audio) %>%
  summarise(n=n(),score=mean.na(score),rating=mean.na(rating))

ggplot(data=d, aes(x=audio,y=score,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none") + 
  labs(title="Guessability by audio version",
       x="audio",
       y="guessability (% correct)") +
  geom_beeswarm(cex=2.5) +
  NULL

ggplot(data=d, aes(x=language,y=score,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() + ylim(0,1) + theme(legend.position="none") + 
  labs(title="Guessability by audio version",
       x="language",
       y="guessability (% correct)") +
  geom_beeswarm(cex=2.5) +
  NULL

# ratings look like they have a distinctly non-normal distribution for field recordings, with a large bulge below 3 (= middle)
ggplot(data=d, aes(x=audio,y=rating,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() +  ylim(1,5) + theme(legend.position="none") + 
  labs(title="Iconicity ratings for 239 ideophones",
       y="mean iconicity rating") +
  geom_beeswarm(cex=2.5) +
  NULL

# and indeed the bulge isn't really there for any of the non-field languages (and arguably mostly attributable to the Semai recordings)
ggplot(data=d, aes(x=language,y=rating,fill=C_cumulative,colour=C_cumulative)) +
  theme_tufte() +  ylim(1,5) + theme(legend.position="none") + 
  labs(title="Iconicity ratings for 239 ideophones",
       x="language",
       y="mean iconicity rating") +
  geom_beeswarm(cex=2.5) +
  NULL


```


```{r congruency_underperformers}
# the reverse is also interesting: which ideophones were coded as having iconic mappings yet were not guessed greatly?

d %>%
  filter(C_cumulative > 0, logodds < -0.25) %>%
  dplyr::select(filename,ideophone,meaning,meaning_NL,C_cumulative,language,logodds,score) %>%
  arrange(score) %>% ungroup() %>%
  slice(1:10)


```
